{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install mxnet\r\n",
    "# !pip install gluonnlp tqdm\r\n",
    "# !pip install sentencepiece\r\n",
    "# !pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import gluonnlp as nlp\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm, tqdm_notebook\r\n",
    "\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from kobert.utils import get_tokenizer\r\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from transformers import AdamW\r\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda:1\")\r\n",
    "# device = torch.device(\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dataset_train = []\r\n",
    "dataset_test = []\r\n",
    "\r\n",
    "root = \"newsData/\"\r\n",
    "list = os.listdir(root)\r\n",
    "for cat in list:\r\n",
    "    files = os.listdir(root + cat)\r\n",
    "    for i,f in enumerate(files):\r\n",
    "        fname = root + cat + \"/\" + f\r\n",
    "        file = open(fname, \"r\", encoding=\"utf-8\")\r\n",
    "        strings = file.read()\r\n",
    "        if i<170:\r\n",
    "            dataset_train.append([strings, cat])\r\n",
    "        else:\r\n",
    "            dataset_test.append([strings,cat])\r\n",
    "        file.close()\r\n",
    "\r\n",
    "print(len(dataset_train), len(dataset_test))\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1360 240\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dataset_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['동남아 담당\\' 北 최희철 부상 베이징 도착…싱가포르행 주목\\t최 부상, 행선지·방문 목적 질문에는 \\'묵묵부답\\'\\n\\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\\n\\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\\n\\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\\n\\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\\n\\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\\n\\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\\n\\n베이징 소식통은 \"최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다\"며 \"만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다\"고 말했다.',\n",
       " '0']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "tokenizer = get_tokenizer()\r\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class BERTDataset(Dataset):\r\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\r\n",
    "        transform = nlp.data.BERTSentenceTransform(\r\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\r\n",
    "\r\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\r\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\r\n",
    "\r\n",
    "    def __getitem__(self, i):\r\n",
    "        return (self.sentences[i] + (self.labels[i], ))\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return (len(self.labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "l1 = [len(i[0]) for i in dataset_train]\r\n",
    "l2 = [len(i[0]) for i in dataset_test]\r\n",
    "max(max(l1),max(l2))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3153"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## Setting parameters\r\n",
    "max_len = 64\r\n",
    "batch_size = 64\r\n",
    "warmup_ratio = 0.1\r\n",
    "num_epochs = 10\r\n",
    "max_grad_norm = 1\r\n",
    "log_interval = 200\r\n",
    "learning_rate =  5e-5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\r\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5, shuffle=True)\r\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class BERTClassifier(nn.Module):\r\n",
    "    def __init__(self,\r\n",
    "                 bert,\r\n",
    "                 hidden_size = 768,\r\n",
    "                 num_classes=8,\r\n",
    "                 dr_rate=None,\r\n",
    "                 params=None):\r\n",
    "        super(BERTClassifier, self).__init__()\r\n",
    "        self.bert = bert\r\n",
    "        self.dr_rate = dr_rate\r\n",
    "                 \r\n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\r\n",
    "        if dr_rate:\r\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\r\n",
    "    \r\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\r\n",
    "        #valid_length 까지만 1, 나머지는 0으로 mask를 생성\r\n",
    "        attention_mask = torch.zeros_like(token_ids)\r\n",
    "        for i, v in enumerate(valid_length):\r\n",
    "            attention_mask[i][:v] = 1\r\n",
    "        return attention_mask.float()\r\n",
    "\r\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\r\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\r\n",
    "        \r\n",
    "        # return_dict=False 추가\r\n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\r\n",
    "\r\n",
    "        #pooler는 CLS토큰에 대한 임베딩의 결과, 단순히 첫번째 토큰에 대한 결과가 아니라 문맥을 알아내기 위한 추가 layer를 통과한다.(아마도?)\r\n",
    "        #임베딩의 결과에 linear layer를 통과시켜서 classification을 진행한다.\r\n",
    "        # print(pooler.shape) batchsize * 768\r\n",
    "\r\n",
    "        #_는 64개(max_length)의 모든 토큰에 대한 임베딩의 결과\r\n",
    "        #단어 임베딩을 알고 싶을 때 사용할 수 있다.\r\n",
    "        #_의 첫번째 값과 pooler와는 다른 값을 가지고 있는데 pooler는 _의 첫번째 값의 추가적으로 한번더 과정을 거친다.\r\n",
    "        #print(_.shape) batchsize * max_len * 768\r\n",
    "\r\n",
    "        if self.dr_rate:\r\n",
    "            out = self.dropout(pooler)\r\n",
    "        return self.classifier(out) #batchsize * num_classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\r\n",
    "optimizer_grouped_parameters = [\r\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\r\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\r\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "t_total = len(train_dataloader) * num_epochs\r\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def calc_accuracy(X,Y):\r\n",
    "    max_vals, max_indices = torch.max(X, 1)\r\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\r\n",
    "    return train_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for e in range(num_epochs):\r\n",
    "    train_acc = 0.0\r\n",
    "    test_acc = 0.0\r\n",
    "    model.train()\r\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\r\n",
    "        optimizer.zero_grad()\r\n",
    "        token_ids = token_ids.long().to(device)\r\n",
    "        segment_ids = segment_ids.long().to(device)\r\n",
    "        valid_length= valid_length\r\n",
    "        label = label.long().to(device)\r\n",
    "        out = model(token_ids, valid_length, segment_ids)\r\n",
    "        loss = loss_fn(out, label)\r\n",
    "        loss.backward()\r\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\r\n",
    "        optimizer.step()\r\n",
    "        scheduler.step()  # Update learning rate schedule\r\n",
    "        train_acc += calc_accuracy(out, label)\r\n",
    "        # if batch_id % log_interval == 0:\r\n",
    "        #     print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\r\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\r\n",
    "    model.eval()\r\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\r\n",
    "        token_ids = token_ids.long().to(device)\r\n",
    "        segment_ids = segment_ids.long().to(device)\r\n",
    "        valid_length= valid_length\r\n",
    "        label = label.long().to(device)\r\n",
    "        out = model(token_ids, valid_length, segment_ids)\r\n",
    "        test_acc += calc_accuracy(out, label)\r\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ubuntu/anaconda3/envs/doheon/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64291b9b9aa4581b52ce6adbbe2ba6b",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 train acc 0.1590909090909091\n",
      "/home/ubuntu/anaconda3/envs/doheon/lib/python3.7/site-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62827083a7824e729a3023377e0062d2",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 test acc 0.2760416666666667\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a5daaef3dc4cf883cab4cc63ac0eda",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 train acc 0.4865056818181818\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14629d8d1e34493292f3518b35b6fb1a",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 test acc 0.73828125\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bbb9552ffc44939c1dfab120dd3405",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 train acc 0.8160511363636364\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe4a1de4437401ab14b78883acaabf0",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 test acc 0.85546875\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d335ab4f8e204d60abf48849f88182f2",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 train acc 0.9069602272727273\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dad428164e047df8eecfb4858c9f155",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 test acc 0.8645833333333334\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554be106db2c4ab0901e3eb1c2f6ff66",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 train acc 0.9502840909090909\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e36876850141b58dce9212277ebabd",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 test acc 0.8854166666666666\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239251e14d8847eaa87502fa0686a8f1",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 train acc 0.9701704545454546\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162effb2f3494723936d9992482e364e",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 test acc 0.8697916666666666\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7beaf36a6dae4be7a4131ca287573a83",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 train acc 0.9772727272727273\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2273047e2114de9b87e642be3f63114",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 test acc 0.87890625\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be043e0ff8404ccb9771e535d5029b12",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 train acc 0.9879261363636364\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20586efe829443c18d5573b251e1c4fe",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 test acc 0.8684895833333334\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2879362b294afcb4360ad5e2875f57",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 train acc 0.9928977272727273\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba80e28360143dca175704a7e467173",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 test acc 0.8671875\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725f1720d2a4afcb8a05b486497546d",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 train acc 0.9928977272727273\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f67367642be4787957477d5a01fced3",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 test acc 0.8684895833333334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def softmax(vals, idx):\r\n",
    "    valscpu = vals.cpu().detach().squeeze(0)\r\n",
    "    a = 0\r\n",
    "    for i in valscpu:\r\n",
    "        a += np.exp(i)\r\n",
    "    return ((np.exp(valscpu[idx]))/a).item() * 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# cate = [\"정치\",\"경제\",\"사회\", \"생활/문화\",\"세계\",\"기술/IT\", \"연예\", \"스포츠\"]\r\n",
    "# tmp = [\"아이패드 프로에 m1칩 탑재\"]\r\n",
    "# transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\r\n",
    "# tokenized = transform(tmp)\r\n",
    "\r\n",
    "# result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\r\n",
    "# idx = result.argmax().cpu().item()\r\n",
    "# print(\"뉴스의 카테고리는:\", cate[idx])\r\n",
    "# print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "torch.save(model.state_dict(), \"news.pt\")\r\n",
    "modelload = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\r\n",
    "modelload.load_state_dict(torch.load(\"news.pt\", device))\r\n",
    "# modelload.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def testModel(model, seq):\r\n",
    "    cate = [\"정치\",\"경제\",\"사회\", \"생활/문화\",\"세계\",\"기술/IT\", \"연예\", \"스포츠\"]\r\n",
    "    tmp = [seq]\r\n",
    "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\r\n",
    "    tokenized = transform(tmp)\r\n",
    "\r\n",
    "    modelload.eval()\r\n",
    "    result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\r\n",
    "    idx = result.argmax().cpu().item()\r\n",
    "    print(\"뉴스의 카테고리는:\", cate[idx])\r\n",
    "    print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "testModel(model, \"신형 아이패드 프로에 m1칩 탑재 예정\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴스의 카테고리는: 기술/IT\n",
      "신뢰도는: 97.48%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(\"vocab의 길이:\",len(vocab.idx_to_token))\r\n",
    "#subtoken 단위로 학습\r\n",
    "print(\"subtokenize 결과:\",tok(\"안녕하세요 going\"))\r\n",
    "vocab.token_to_idx[\"▁안\"]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocab의 길이: 8002\n",
      "subtokenize 결과: ['▁안', '녕', '하세요', '▁', 'go', 'ing']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3135"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 단일 문장 테스트\r\n",
    "tmp = [\"안녕하세요 going\"]\r\n",
    "transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\r\n",
    "print(\"tokenize:\",transform(tmp)[0])\r\n",
    "print(\"length:\",transform(tmp)[1])\r\n",
    "print(\"token_type_id:\", transform(tmp)[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenize: [   2 3135 5724 7814  517  400  410    3    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1]\n",
      "length: 8\n",
      "token_type_id: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# vocab.token_to_idx.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "849767edceeeddf53965c2c22dc0d6f4cc62af5f2af22e684245cca2d0b8102d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}